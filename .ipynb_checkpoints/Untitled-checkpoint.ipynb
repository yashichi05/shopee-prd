{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yahoo 下架會正常\n",
    "pdid = \"100443243712\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "url = \"https://tw.bid.yahoo.com/item/\"+pdid\n",
    "my_headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "gotrq = requests.get(url,headers = my_headers)\n",
    "soup = BeautifulSoup(gotrq.text, \"html.parser\") #\"html.parser\" html解析器 將html 轉為bs4格式操作\n",
    "#for item in soup.select(\".listing-title\"): #html 可以使用select 選擇想要的東西\n",
    "    #print(item.select(\"a\")[0].text)\n",
    "gotjson = soup.select(\"#isoredux-data\")[0].get(\"data-state\") #get 取得屬性\n",
    "load = json.loads(gotjson)  #轉成python dict\n",
    "\n",
    "for i in range(len(load[\"item\"][\"models\"])): #提取ID\n",
    "    specnameID = str(load[\"item\"][\"models\"][i][\"specCombination\"]).split(\":\")\n",
    "    specname = str(load[\"item\"][\"specs\"][0]['options'][i]['name'])\n",
    "    if specnameID[1] == str(load[\"item\"][\"specs\"][0]['options'][i]['id']):\n",
    "        text = '驗證成功 '\n",
    "    \n",
    "    print(text+load[\"item\"][\"models\"][i][\"id\"]+\":\"+ str(load[\"item\"][\"models\"][i][\"qty\"])+\" \"+specname)\n",
    "print(str(load[\"item\"][\"status\"])+\"   ● 2:上架,3:下架\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344966001:64 玫瑰\n",
      "344966002:82 薄荷\n"
     ]
    }
   ],
   "source": [
    "#蝦皮 下架商品會是0\n",
    "pdid = \"446709984\"\n",
    "load = \"\" #重製\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() #新增chrome選項\n",
    "chrome_options.add_argument('--headless') #隱藏GUI\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome('chromedriver.exe',chrome_options = chrome_options) \n",
    "browser.get('https://shopee.tw/product/2019696/'+pdid) \n",
    "time.sleep(1) #第一次讀取會失敗 可能要加點選事件，或是觀看視窗的事件 資料可能放在dataLayer[5] #判斷4有無值，無值則layer[5]\n",
    "browser.find_element_by_css_selector(\"input.shopee-button-outline\").click()\n",
    "try:\n",
    "    browser.execute_script(\"return document.getElementById('main').innerHTML = JSON.stringify(dataLayer[4].info.impressions[0].targetData.item)\")\n",
    "    if browser.find_element_by_id('main').text == 'undefined': #如果沒有值，則找layer5\n",
    "        browser.execute_script(\"return document.getElementById('main').innerHTML = JSON.stringify(dataLayer[5].info.impressions[0].targetData.item)\")\n",
    "    gotjson = browser.find_element_by_id('main').text #取得JSON\n",
    "    load = json.loads(gotjson)\n",
    "    if len(load['models']) == 0: #判斷有沒有款式\n",
    "        print(load['stock'])\n",
    "    else:\n",
    "        for i in range(len(load['models'])):\n",
    "            print(str(load['models'][i]['modelid'])+\":\"+str(load['models'][i]['stock'])+\" \"+str(load['models'][i]['name']))    \n",
    "except:\n",
    "    print('...')\n",
    "finally:\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "url = \"https://shopee.tw/api/v1/item_detail/?item_id=30324026&shop_id=2019696\"\n",
    "my_headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "cookie = {'value': 'f6d90f8e-b763-11e8-9f87-b496912770ce'}\n",
    "gotrq = requests.get(url,headers = my_headers,cookies = cookie)\n",
    "api = json.loads(gotrq.text) #\"html.parser\" html解析器 將html 轉為bs4格式操作\n",
    "#for item in soup.select(\".listing-title\"): #html 可以使用select 選擇想要的東西\n",
    "    #print(item.select(\"a\")[0].text)\n",
    "print(gotrq.cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruten #下架商品會正常\n",
    "pdid = \"21738136998850\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "url = \"https://goods.ruten.com.tw/item/show?\"+pdid\n",
    "my_headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "gotrq = requests.get(url,headers = my_headers)\n",
    "soup = BeautifulSoup(gotrq.text, \"html.parser\") #\"html.parser\" html解析器 將html 轉為bs4格式操作\n",
    "strnum = soup.select('script[type=\"text/javascript\"]')[16].text.find(\"RT.context = \") #提取JSON資料 #find 找到RT.context的位址\n",
    "gotjson = soup.select('script[type=\"text/javascript\"]')[16].text[strnum+len(\"RT.context = \"):-2]\n",
    "load = json.loads(gotjson)  #轉成python dict\n",
    "if 'spec_info' in load.keys(): #是否有款式\n",
    "    for k,v in load['spec_info']['specs'].items():#for 出dict 資料\n",
    "        print(k+':'+v['spec_num']+\" \"+v['spec_name'])\n",
    "else:\n",
    "    print(load['remain_count'])\n",
    "print(\"有上架嗎?\"+str(load['is_product_buyer']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:480 \n"
     ]
    }
   ],
   "source": [
    "#PC \n",
    "pdid = \"C1139763580\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "url = \"http://seller.pcstore.com.tw/S188431702/\"+pdid+\".htm\"\n",
    "my_headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "gotrq = requests.get(url,headers = my_headers)\n",
    "soup = BeautifulSoup(gotrq.text, \"html.parser\") #\"html.parser\" html解析器 將html 轉為bs4格式操作\n",
    "gotjson = soup.select('#specs')[0].text\n",
    "load = json.loads(gotjson)\n",
    "\n",
    "if type(load) == dict: #新上的都是字典檔\n",
    "    for k,v in load.items():\n",
    "        print(v['p_sseq']+\":\"+v['p_invt']+\" \"+v['p_spec'])\n",
    "else:#舊的都是陣列\n",
    "    for i in range(len(load)):\n",
    "        print(load[i]['p_sseq']+\":\"+load[i]['p_invt']+\" \"+load[i]['p_spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC 梓原 #下架會錯誤\n",
    "pdid = \"C1142301095\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "url = \"http://seller.pcstore.com.tw/S163498400/\"+pdid+\".htm\"\n",
    "my_headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "gotrq = requests.get(url,headers = my_headers)\n",
    "soup = BeautifulSoup(gotrq.text, \"html.parser\") #\"html.parser\" html解析器 將html 轉為bs4格式操作\n",
    "gotjson = soup.select('#specs')[0].text\n",
    "load = json.loads(gotjson)\n",
    "\n",
    "if type(load) == dict: #新上的都是字典檔\n",
    "    for k,v in load.items():\n",
    "        print(v['p_sseq']+\":\"+v['p_invt']+\" \"+v['p_spec'])\n",
    "else:#舊的都是陣列\n",
    "    for i in range(len(load)):\n",
    "        print(load[i]['p_sseq']+\":\"+load[i]['p_invt']+\" \"+load[i]['p_spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-16bb730a2b8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mstrnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'script'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"window._pc_p = \"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#提取JSON資料\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgotjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'script'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrnum\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"window._pc_p = \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgotjson\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#轉成python dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'volumes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#pcone #下架商品會錯誤\n",
    "pdid = \"180126442661\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "url = \"https://www.pcone.com.tw/product/info/\"+pdid\n",
    "my_headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "gotrq = requests.get(url,headers = my_headers)\n",
    "soup = BeautifulSoup(gotrq.text, \"html.parser\") #\"html.parser\" html解析器 將html 轉為bs4格式操作\n",
    "strnum = soup.select('script')[23].text.find(\"window._pc_p = \") #提取JSON資料\n",
    "gotjson = soup.select('script')[23].text[strnum+len(\"window._pc_p = \"):-2]\n",
    "load = json.loads(gotjson)  #轉成python dict\n",
    "\n",
    "for i in range(len(load['volumes'])):\n",
    "    print(str(load['volumes'][i]['volume_id'])+\":\"+str(load['volumes'][i]['volume_remaining'])+\" \"+str(load['volumes'][i]['option']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取\n",
    "#第一次執行需要用CMD執行 才會跑出網頁認證\n",
    "from __future__ import print_function\n",
    "from googleapiclient.discovery import build\n",
    "from httplib2 import Http\n",
    "from oauth2client import file, client, tools\n",
    "\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = 'https://www.googleapis.com/auth/spreadsheets'\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Shows basic usage of the Sheets API.\n",
    "    Prints values from a sample spreadsheet.\n",
    "    \"\"\"\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        flow = client.flow_from_clientsecrets('credentials.json', SCOPES)\n",
    "        creds = tools.run_flow(flow, store)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "\n",
    "    # Call the Sheets API\n",
    "    SPREADSHEET_ID = '19ZXwhENPrLmLURoKO4xXoCDahpyMG5wuU_8xsU74kyI'\n",
    "    RANGE_NAME = '商品ID!A:Q'\n",
    "    result = service.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                                range=RANGE_NAME).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('No data found.')\n",
    "    else:\n",
    "        global resultdata\n",
    "        resultdata= values\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spreadsheetId': '19ZXwhENPrLmLURoKO4xXoCDahpyMG5wuU_8xsU74kyI', 'clearedRanges': [\"'庫存表'!M1:M2000\"]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "delsheet(\"'庫存表'!M:M\") #重製狀態欄\n",
    "writetime = time.strftime(\"%m-%d %H:%M\", time.localtime()) \n",
    "datay = []\n",
    "datar = []\n",
    "datas = []\n",
    "datapt = []\n",
    "datapd = []\n",
    "datapcone = []\n",
    "for row in range(1,len(resultdata)):\n",
    "    datay.append(resultdata[row][4])\n",
    "    datar.append(resultdata[row][6])\n",
    "    datas.append(resultdata[row][8])\n",
    "    datapt.append(resultdata[row][10])\n",
    "    datapd.append(resultdata[row][12])\n",
    "    datapcone.append(resultdata[row][14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lastindexof'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4aff1b570f33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mwebID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresultdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#蝦皮\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwebID\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#有值則執行\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlastindexof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwebID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mwebID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresultdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#PC梓\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwebID\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#有值則執行\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lastindexof'"
     ]
    }
   ],
   "source": [
    "for row in range(1,5):\n",
    "    webID = resultdata[row][4] #yahoo\n",
    "    if webID: #有值則執行\n",
    "        datay.lastindexof(webID)\n",
    "\n",
    "    webID = resultdata[row][6] #露天\n",
    "    if webID: #有值則執行\n",
    "        print(webID)\n",
    "    webID = resultdata[row][8] #蝦皮\n",
    "    if webID: #有值則執行\n",
    "        print(datay.lastindexof(webID))\n",
    "    webID = resultdata[row][10] #PC梓\n",
    "    if webID: #有值則執行\n",
    "        print(webID)\n",
    "    webID = resultdata[row][12] #PC大\n",
    "    if webID: #有值則執行\n",
    "        print(webID)\n",
    "    webID = resultdata[row][14] #松果\n",
    "    if webID: #有值則執行\n",
    "        print(webID)\n",
    "    #執行完成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寫入\n",
    "#第一次執行需要用CMD執行 才會跑出網頁認證 SCOPE不一樣 TOKEN.JSON要刪掉重新刷過\n",
    "from __future__ import print_function\n",
    "from googleapiclient.discovery import build\n",
    "from httplib2 import Http\n",
    "from oauth2client import file, client, tools\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = 'https://www.googleapis.com/auth/spreadsheets'\n",
    "\n",
    "def writesheet(sheetrange,writeVal):\n",
    "    \"\"\"Shows basic usage of the Sheets API.\n",
    "    Prints values from a sample spreadsheet.\n",
    "    \"\"\"\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        flow = client.flow_from_clientsecrets('credentials.json', SCOPES)\n",
    "        creds = tools.run_flow(flow, store)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "\n",
    "    # Call the Sheets API\n",
    "    SPREADSHEET_ID = '19ZXwhENPrLmLURoKO4xXoCDahpyMG5wuU_8xsU74kyI'\n",
    "    RANGE_NAME = sheetrange\n",
    "    values =[['=52+25']]\n",
    "    body = {'values': writeVal}\n",
    "    value_input_option = 'USER_ENTERED'\n",
    "    result = service.spreadsheets().values().update(spreadsheetId=SPREADSHEET_ID,range=RANGE_NAME,valueInputOption=value_input_option,body=body).execute()\n",
    "    print(result)\n",
    "    \n",
    "def delsheet(sheetrange):\n",
    "    \"\"\"Shows basic usage of the Sheets API.\n",
    "    Prints values from a sample spreadsheet.\n",
    "    \"\"\"\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        flow = client.flow_from_clientsecrets('credentials.json', SCOPES)\n",
    "        creds = tools.run_flow(flow, store)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "\n",
    "    # Call the Sheets API\n",
    "    SPREADSHEET_ID = '19ZXwhENPrLmLURoKO4xXoCDahpyMG5wuU_8xsU74kyI'\n",
    "    RANGE_NAME = {'ranges' : [sheetrange]}\n",
    "    result = service.spreadsheets().values().batchClear(spreadsheetId=SPREADSHEET_ID,body=RANGE_NAME).execute()\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "OK = [] #完成的網頁放這邊\n",
    "for row in range(1,10):\n",
    "    webID = resultdata[row][8] #蝦皮\n",
    "    if webID and (OK.count(webID) == 0): #有網頁ID則執行且沒執行過的\n",
    "        OK.append(webID)\n",
    "        #執行DEF(webID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['webID',\n",
       " 'webID',\n",
       " 'webID',\n",
       " 'webID',\n",
       " 'webID',\n",
       " 'webID',\n",
       " 'webID',\n",
       " 'webID',\n",
       " 'webID']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
